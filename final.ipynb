{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129c3cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import pickle\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\"\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba25996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.getcwd() + \"/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + \"train\" + \"/\" + city + \"_inputs\"\n",
    "    #print(f_in)\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        \n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "        \n",
    "    if split==\"val_train\":\n",
    "        f_out = ROOT_PATH + \"train\" + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        \n",
    "        length = len(inputs)\n",
    "        split_size = int(length * 0.8)\n",
    "        outputs = np.asarray(outputs)[:split_size]\n",
    "        inputs = inputs[:split_size]\n",
    "        \n",
    "    if split==\"val\":\n",
    "        f_out = ROOT_PATH + \"train\" + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        \n",
    "        length = len(inputs)\n",
    "        split_size = int(length * 0.8)\n",
    "        outputs = np.asarray(outputs)[split_size:]\n",
    "        inputs = inputs[split_size:]\n",
    "        \n",
    "    return inputs, outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69abe6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.city = city\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=True)\n",
    "        self.global_mean = np.mean(self.inputs, axis = (0,1), keepdims = True)\n",
    "        self.global_std = np.std(np.sqrt(self.inputs[:, :, 0]**2 + self.inputs[:, :, 0]**2))\n",
    "        self.inputs = (self.inputs - self.global_mean)/self.global_std\n",
    "        \n",
    "        if split != 'test' or split != 'val':\n",
    "            self.outputs = (self.outputs - self.global_mean)/self.global_std    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.split == \"train\" or self.split == \"val_train\" or self.split == \"val\":\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        else:\n",
    "            data = self.inputs[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec29485",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85/1644615986.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_85/1644615986.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, out_dim)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \"\"\"\n\u001b[1;32m      5\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdefines\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LR' is not defined"
     ]
    }
   ],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super(LR, self).__init__()\n",
    "        \"\"\"\n",
    "        the __init__() method that defines the layers and other components\n",
    "        \"\"\" \n",
    "        self.model = nn.Linear(input_dim, out_dim) # input_dim = input_length*2\n",
    "        \n",
    "    def forward(self, x, output_steps): \n",
    "        \"\"\"\n",
    "        the forward function is where computatioin gets done\n",
    "        \"\"\"\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(output_steps):\n",
    "            out = self.model(x)    \n",
    "            outputs.append(out)\n",
    "            x = torch.cat([x[:,2:],  out], dim = 1)\n",
    "            \n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "        return outputs.reshape(outputs.shape[0], output_steps, 2)\n",
    "    \n",
    "model = LinearRegression(input_dim = 50 * 2, out_dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ecfe4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_rate):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_dim, \n",
    "                            hidden_size = hidden_dim, \n",
    "                            num_layers= num_layers, \n",
    "                            dropout = dropout_rate, \n",
    "                            batch_first = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, source):\n",
    "        \n",
    "        # hidden = (h, c)\n",
    "        # h, c: num_layers x bz x  hid_dim\n",
    "        # outputs: bz x input_length x hid_dim\n",
    "        outputs, hidden = self.lstm(source)\n",
    "        \n",
    "        return outputs, hidden\n",
    "    \n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers, dropout_rate):\n",
    "\n",
    "        super(AttnDecoder, self).__init__()\n",
    "\n",
    "        # Learn the attention scores\n",
    "        self.attn = nn.Linear(hidden_dim + output_dim, 50)\n",
    "        \n",
    "        # Learn the final input to the decoder \n",
    "        self.attn_combine = nn.Linear(hidden_dim + output_dim, hidden_dim)\n",
    "        \n",
    "        # Decoder LSTM\n",
    "        self.lstm = nn.LSTM(input_size = hidden_dim, \n",
    "                            hidden_size = hidden_dim, \n",
    "                            num_layers= num_layers, \n",
    "                            dropout = dropout_rate, \n",
    "                            batch_first = True)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "      \n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        \n",
    "        h = hidden[0]\n",
    "        h = h.transpose(0,1).reshape(h.shape[1], -1)\n",
    "        \n",
    "        # Compute Attention Scores\n",
    "        attn_weights = F.softmax(self.attn(torch.cat([x, h], 1)), dim =1)\n",
    "        \n",
    "        # Calculate weighted sum of encoder hidden states     \n",
    "        attn_applied = torch.einsum(\"bl,blh->bh\", attn_weights, encoder_outputs)\n",
    "        \n",
    "        x = torch.cat((x, attn_applied), dim = 1)\n",
    "        x = self.attn_combine(x).unsqueeze(1)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        output, decoder_hidden= self.lstm(x, hidden)  \n",
    "        prediction = self.output_layer(output.float())\n",
    "        \n",
    "        return prediction.squeeze(1), decoder_hidden\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim = 2, output_dim = 2, hidden_dim = 128, num_layers = 1, dropout_rate = 0.3):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, num_layers, dropout_rate)\n",
    "        self.decoder = AttnDecoder(output_dim, hidden_dim, num_layers, dropout_rate)\n",
    "\n",
    "    def forward(self, source, target_length):\n",
    "\n",
    "        batch_size = source.size(0) \n",
    "        input_length = source.size(1) \n",
    "        \n",
    "        encoder_outputs, concat_hidden = self.encoder(source)\n",
    "        \n",
    "        # the last encoder hidden state is used as initial hidden state of the decoder\n",
    "        decoder_hidden = concat_hidden\n",
    "        # the first input to the decoder is last input position\n",
    "        decoder_output = source[:,-1]\n",
    "    \n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_length, 2)\n",
    "        for t in range(target_length):    \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_output, decoder_hidden, encoder_outputs)\n",
    "            outputs[:,t] = decoder_output   \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73e4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 128  # batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7f2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        ).to(device)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120)\n",
    "        ).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.reshape(-1, 60, 2)\n",
    "        x = x.to(device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8888877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city: austin epoch 0: loss = 94.86022264137864\n",
      "city: austin epoch 1: loss = 4.767970793880522\n",
      "city: austin epoch 2: loss = 0.4295295405900106\n",
      "city: austin epoch 3: loss = 0.2657199546811171\n",
      "city: austin epoch 4: loss = 0.20560628804378211\n",
      "city: austin epoch 5: loss = 0.17916903569130227\n",
      "city: austin epoch 6: loss = 0.16435696854023263\n",
      "city: austin epoch 7: loss = 0.15508097945712507\n",
      "city: austin epoch 8: loss = 0.14913996600080281\n",
      "city: austin epoch 9: loss = 0.145627606427297\n",
      "city: austin loss = 3.4420418736872143e-06\n",
      "city: miami epoch 0: loss = 84.21882901899517\n",
      "city: miami epoch 1: loss = 1.9461548190156464\n",
      "city: miami epoch 2: loss = 0.10735352434130618\n",
      "city: miami epoch 3: loss = 0.04538698252508766\n",
      "city: miami epoch 4: loss = 0.03163025977482903\n",
      "city: miami epoch 5: loss = 0.027421483799116686\n",
      "city: miami epoch 6: loss = 0.025405450054677203\n",
      "city: miami epoch 7: loss = 0.0242761859226448\n",
      "city: miami epoch 8: loss = 0.023760712010698626\n",
      "city: miami epoch 9: loss = 0.023288956261239946\n",
      "city: miami loss = 4.0448302656786497e-07\n",
      "city: pittsburgh epoch 0: loss = 59.140771478414536\n",
      "city: pittsburgh epoch 1: loss = 5.381823935662396\n",
      "city: pittsburgh epoch 2: loss = 0.13035670030512847\n",
      "city: pittsburgh epoch 3: loss = 0.08068637664837297\n",
      "city: pittsburgh epoch 4: loss = 0.06743583775823936\n",
      "city: pittsburgh epoch 5: loss = 0.06167662757798098\n",
      "city: pittsburgh epoch 6: loss = 0.05876798465033062\n",
      "city: pittsburgh epoch 7: loss = 0.05691933902562596\n",
      "city: pittsburgh epoch 8: loss = 0.05555346054461552\n",
      "city: pittsburgh epoch 9: loss = 0.054510423018655274\n",
      "city: pittsburgh loss = 1.1909515574394664e-06\n",
      "city: dearborn epoch 0: loss = 44.003238309174776\n",
      "city: dearborn epoch 1: loss = 2.2018811479210854\n",
      "city: dearborn epoch 2: loss = 1.8002700824290514\n",
      "city: dearborn epoch 3: loss = 1.6432989253662527\n",
      "city: dearborn epoch 4: loss = 0.9606838735635392\n",
      "city: dearborn epoch 5: loss = 0.17851143865846097\n",
      "city: dearborn epoch 6: loss = 0.05676674991264008\n",
      "city: dearborn epoch 7: loss = 0.03275056101119844\n",
      "city: dearborn epoch 8: loss = 0.02597477198287379\n",
      "city: dearborn epoch 9: loss = 0.022674526888295077\n",
      "city: dearborn loss = 9.421173776411599e-07\n",
      "city: washington-dc epoch 0: loss = 48.00417033210397\n",
      "city: washington-dc epoch 1: loss = 8.665333118289709\n",
      "city: washington-dc epoch 2: loss = 2.6682607140392065\n",
      "city: washington-dc epoch 3: loss = 0.5303306191926822\n",
      "city: washington-dc epoch 4: loss = 0.13770812851726077\n",
      "city: washington-dc epoch 5: loss = 0.08057254548475612\n",
      "city: washington-dc epoch 6: loss = 0.06229076595627703\n",
      "city: washington-dc epoch 7: loss = 0.053799697881913744\n",
      "city: washington-dc epoch 8: loss = 0.04952986210992094\n",
      "city: washington-dc epoch 9: loss = 0.04705597291467711\n",
      "city: washington-dc loss = 1.7242080141169988e-06\n",
      "city: palo-alto epoch 0: loss = 115.91016936302185\n",
      "city: palo-alto epoch 1: loss = 69.53127798438072\n",
      "city: palo-alto epoch 2: loss = 39.37761268019676\n",
      "city: palo-alto epoch 3: loss = 10.340794779360294\n",
      "city: palo-alto epoch 4: loss = 0.7105836365371943\n",
      "city: palo-alto epoch 5: loss = 0.3095385928172618\n",
      "city: palo-alto epoch 6: loss = 0.23843321041204035\n",
      "city: palo-alto epoch 7: loss = 0.20987661485560238\n",
      "city: palo-alto epoch 8: loss = 0.1932813881430775\n",
      "city: palo-alto epoch 9: loss = 0.181617715745233\n",
      "city: palo-alto loss = 1.5914852966084e-05\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sample_submission.csv', index_col='ID')\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "def run_model(city):\n",
    "    \n",
    "    model = EncoderModel()\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    train_dataset = ArgoverseDataset(city = city, split = \"train\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_sz)\n",
    "    global_std = train_dataset.global_std\n",
    "    global_mean = train_dataset.global_mean\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        total_loss = 0\n",
    "        for i_batch, sample_batch in enumerate(train_loader):\n",
    "            inp, out = sample_batch\n",
    "            inp = inp.float().to(device)\n",
    "            out = out.float().to(device)\n",
    "            preds = model(inp)\n",
    "            preds = preds.float().to(device)\n",
    "            loss = criterion(preds, out)\n",
    "#             inversedPreds = preds.detach().numpy() * global_std * global_mean\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print('city: {} epoch {}: loss = {}'.format(city, epoch, total_loss))\n",
    "#     predict(city, model)\n",
    "    validate(model, city)\n",
    "    \n",
    "    \n",
    "def predict(city, model):\n",
    "    \n",
    "    test_dataset  = ArgoverseDataset(city = city, split = 'test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_sz)\n",
    "    \n",
    "    global_std = test_dataset.global_std\n",
    "    global_mean = test_dataset.global_mean\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(test_loader):\n",
    "        inp = sample_batch\n",
    "        inp = inp.float().to(device)\n",
    "        preds = model(inp)\n",
    "        preds = preds.detach().numpy() * global_std + global_mean\n",
    "        for i in range(len(preds[0])):\n",
    "            for j in range(len(preds)):\n",
    "                row = str(i_batch * batch_sz + j) + \"_\" + city\n",
    "                x_col = \"v\" + str(2 * i)\n",
    "                y_col = \"v\" + str(2 * i + 1)\n",
    "                df.loc[row, x_col] = preds[j][i][0].item()\n",
    "                df.loc[row, y_col] = preds[j][i][1].item()\n",
    "        \n",
    "    df.to_csv('sample_submission.csv')\n",
    "    \n",
    "def validate(model, city):\n",
    "    \n",
    "    total_loss = 0\n",
    "    val_dataset = ArgoverseDataset(city = city, split = \"val\")\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_sz)\n",
    "    global_std = val_dataset.global_std\n",
    "    global_mean = val_dataset.global_mean\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(val_loader):\n",
    "        inp, out = sample_batch\n",
    "        inp = inp.float().to(device)\n",
    "        preds = model(inp)\n",
    "        preds = preds.float().to(device)\n",
    "        loss = criterion(preds, out.to(device))\n",
    "        total_loss += loss.item()\n",
    "    print('city: {} loss = {}'.format(city, total_loss / len(val_dataset)))\n",
    "            \n",
    "for city in cities:\n",
    "    run_model(city)\n",
    "# run_model(\"palo-alto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaf460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332ca86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
